{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11454195,"sourceType":"datasetVersion","datasetId":5211395}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! git clone https://github.com/tangha1004/thesis.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:52:10.431872Z","iopub.execute_input":"2025-08-29T07:52:10.432437Z","iopub.status.idle":"2025-08-29T07:52:11.193803Z","shell.execute_reply.started":"2025-08-29T07:52:10.432410Z","shell.execute_reply":"2025-08-29T07:52:11.192896Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'thesis'...\nremote: Enumerating objects: 92, done.\u001b[K\nremote: Counting objects: 100% (92/92), done.\u001b[K\nremote: Compressing objects: 100% (62/62), done.\u001b[K\nremote: Total 92 (delta 59), reused 61 (delta 28), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (92/92), 330.32 KiB | 10.32 MiB/s, done.\nResolving deltas: 100% (59/59), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd '/kaggle/working/thesis'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:52:11.194936Z","iopub.execute_input":"2025-08-29T07:52:11.195412Z","iopub.status.idle":"2025-08-29T07:52:11.201603Z","shell.execute_reply.started":"2025-08-29T07:52:11.195369Z","shell.execute_reply":"2025-08-29T07:52:11.200668Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/thesis\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"! git pull origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:52:11.203312Z","iopub.execute_input":"2025-08-29T07:52:11.203499Z","iopub.status.idle":"2025-08-29T07:52:11.627475Z","shell.execute_reply.started":"2025-08-29T07:52:11.203484Z","shell.execute_reply":"2025-08-29T07:52:11.626569Z"}},"outputs":[{"name":"stdout","text":"From https://github.com/tangha1004/thesis\n * branch            main       -> FETCH_HEAD\nAlready up to date.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **0. Import**","metadata":{}},{"cell_type":"markdown","source":"## **0.1. Import basic libraries**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport os\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display, HTML\n!pip install watermark --quiet\nimport random\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay,\n    accuracy_score,\n)\n\n%cd '/kaggle/working/thesis/models_VAE'\nfrom models import init_model_dict_multi\nfrom utils import save_model_dict, load_model_dict\nfrom train_test import prepare_trte_data, train_test, train_epoch, test_epoch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:52:11.628761Z","iopub.execute_input":"2025-08-29T07:52:11.629030Z","iopub.status.idle":"2025-08-29T07:52:21.255706Z","shell.execute_reply.started":"2025-08-29T07:52:11.628996Z","shell.execute_reply":"2025-08-29T07:52:21.254968Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/thesis/models_VAE\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import sklearn\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nimport copy\nfrom sklearn.compose import ColumnTransformer \nfrom IPython.display import Markdown\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\nfrom scipy.stats import mode\nfrom datetime import datetime\n\n!pip install captum --quiet\nfrom captum.attr import IntegratedGradients, GradientShap","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:52:21.256550Z","iopub.execute_input":"2025-08-29T07:52:21.256994Z","iopub.status.idle":"2025-08-29T07:53:34.960573Z","shell.execute_reply.started":"2025-08-29T07:52:21.256972Z","shell.execute_reply":"2025-08-29T07:53:34.959700Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"cuda = True if torch.cuda.is_available() else False\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'cuda: {cuda}')\n\ndef set_seed(seed: int = 42) -> None:\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    print(f\"Random seed set as {seed}\")\n\n# Config\nrseed = 42\nset_seed(rseed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:53:34.961778Z","iopub.execute_input":"2025-08-29T07:53:34.962006Z","iopub.status.idle":"2025-08-29T07:53:34.973140Z","shell.execute_reply.started":"2025-08-29T07:53:34.961979Z","shell.execute_reply":"2025-08-29T07:53:34.972366Z"}},"outputs":[{"name":"stdout","text":"cuda: True\nRandom seed set as 42\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## **0.2. List hyperparameters**","metadata":{}},{"cell_type":"code","source":"# no space to pass through cmd\nview_list = [1,2,3]\nidx_list = [1,2,3]\nhidden_dim = [1024,1024,1024]\ninput_dim = [2000,2000,2000]\nlatent_space_dim = int((len(view_list) - 1) * 256)\nlevel_2_dim = [1024,1024,1024]\nlevel_3_dim = [512,512,512]\n# num_omics x level_2_dim ---> level_4_dim\nlevel_4_dim = int(len(view_list) * 256)\nclassifier_1_dim = int((len(view_list) - 1) * 128)\nclass_num = 4\nnum_class = 4\n\nprint_hyper = False\nverbose = False\ntestonly = False\n\ndataset_name = 'tcga-gbm-methxgexcnv-2000-3-omics'\nCOHORT = 'TCGA_GBM_METHxGExCNV_2000x2000x2000_MinMaxScaler'\ndata_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\nmodel_folder = '/kaggle/working/models'\ntrain_file = '/kaggle/working/thesis/models_VAE/main.py'\n\nnum_epoch = 200\nlr = 0.001\nbatch_size = 32\npatience = 23\nk_view_list = [1.0,1.0,1.0]\nk_kl = 1.0\nk_c = 1.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:09:36.016841Z","iopub.execute_input":"2025-08-29T08:09:36.017398Z","iopub.status.idle":"2025-08-29T08:09:36.023459Z","shell.execute_reply.started":"2025-08-29T08:09:36.017368Z","shell.execute_reply":"2025-08-29T08:09:36.022771Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"get_name = COHORT.count('_') + 3\n\npostfix_tr = '_tr'\npostfix_te = '_val'\n\ndata_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\nmodel_folder = '/kaggle/working/models'\ntrain_file = '/kaggle/working/thesis/models_VAE/main.py'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:53:34.992032Z","iopub.execute_input":"2025-08-29T07:53:34.992623Z","iopub.status.idle":"2025-08-29T07:53:35.005356Z","shell.execute_reply.started":"2025-08-29T07:53:34.992603Z","shell.execute_reply":"2025-08-29T07:53:35.004802Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"loc_file_json_id_omic = data_folder + '/1/dct_index_subtype.json'\nwith open(loc_file_json_id_omic) as file_json_id_omic:\n    dct_LABEL_MAPPING_NAME = json.load(file_json_id_omic)\n    # dct_LABEL_MAPPING_NAME = {int(k): v for k,v in dct_LABEL_MAPPING_NAME.items()} # convert str number key to int\nLABEL_MAPPING_NAME = dct_LABEL_MAPPING_NAME.values()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:53:35.007575Z","iopub.execute_input":"2025-08-29T07:53:35.008110Z","iopub.status.idle":"2025-08-29T07:53:35.038720Z","shell.execute_reply.started":"2025-08-29T07:53:35.008093Z","shell.execute_reply":"2025-08-29T07:53:35.038125Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"for fold_id in [3]:\n#     print(f'idx data: {fold_id}')\n    tmp = list(LABEL_MAPPING_NAME)\n    label_files = ['tr', 'te', 'val']\n    dict = {\n        'tr': 'Train set',\n        'te': 'Test set',\n        'val': 'Validation set'\n    }\n    \n    print('\\nCount per Subtypes: \\n')\n    for label_file in label_files:\n        df = pd.read_csv(f'{data_folder}/{fold_id}/labels_{label_file}.csv', header=None, names=['subtypes'])\n        subtype_counts = df['subtypes'].value_counts().sort_index()\n        \n        print(f'{dict[label_file]}')\n        \n        res = {}\n        for subtype, count in subtype_counts.items():\n            res[tmp[subtype]] = count\n\n        print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')\n    \n    print('\\nCount Samples: \\n')\n    for idx in view_list:\n        res = {}\n        for label_file in label_files:\n            df = pd.read_csv(f'{data_folder}/{fold_id}/{idx}_{label_file}.csv', header=None)\n            res[dict[label_file]] = df.shape[0]\n            \n        print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')\n    \n    print('\\nCount Features: \\n')\n    res={}\n    for idx in view_list:\n        df = pd.read_csv(f'{data_folder}/{fold_id}/{idx}_featname.csv', header=None, names=['featname'])\n        res[f\"Omic {idx}\"] = df.shape[0]\n        \n    print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:53:35.039369Z","iopub.execute_input":"2025-08-29T07:53:35.039531Z","iopub.status.idle":"2025-08-29T07:53:36.000738Z","shell.execute_reply.started":"2025-08-29T07:53:35.039519Z","shell.execute_reply":"2025-08-29T07:53:35.999989Z"}},"outputs":[{"name":"stdout","text":"\nCount per Subtypes: \n\nTrain set\n Classical  Mesenchymal  Neural  Proneural\n        43           48      28         43 \n\nTest set\n Classical  Mesenchymal  Neural  Proneural\n        14           16       9         15 \n\nValidation set\n Classical  Mesenchymal  Neural  Proneural\n        14           17       9         14 \n\n\nCount Samples: \n\n Train set  Test set  Validation set\n       162        54              54 \n\n Train set  Test set  Validation set\n       162        54              54 \n\n Train set  Test set  Validation set\n       162        54              54 \n\n\nCount Features: \n\n Omic 1  Omic 2  Omic 3\n   2000    2000    2000 \n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"added_softmax = False\n\ndef preprocessing_data(tup_tensor_test_data, data_folder):\n    data_tr_list = []\n    data_te_list = []\n    \n    for i in view_list:\n        data_tr_list.append(torch.tensor(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','),dtype=torch.float32))\n        data_te_list.append(tup_tensor_test_data[i-1])\n        if cuda:\n            data_tr_list[i-1] = data_tr_list[i-1].to(device)\n            data_te_list[i-1] = data_te_list[i-1].to(device)       \n\n    num_tr = data_tr_list[0].shape[0]\n    num_te = data_te_list[0].shape[0]\n    trte_idx = {}\n    trte_idx[\"tr\"] = list(range(num_tr))\n    trte_idx[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n\n    num_view = len(view_list)\n    data_tensor_list = []\n    for i in range(num_view):\n        data_tensor_list.append(torch.cat((data_tr_list[i], data_te_list[i]), axis=0))\n        if cuda:\n            data_tensor_list[i] = data_tensor_list[i].to(device)#cuda()\n    \n    data_train_list = []\n    data_trte_list = []\n    for i in range(len(data_tensor_list)):\n        data_train_list.append(data_tensor_list[i][trte_idx[\"tr\"]].clone())\n\n        tup_seq_data = (data_tensor_list[i][trte_idx[\"tr\"]].clone(), data_tensor_list[i][trte_idx[\"te\"]].clone())\n        data_trte_list.append(\n            torch.cat(tup_seq_data,axis=0)\n        )\n    return data_train_list, data_trte_list,trte_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:53:36.001522Z","iopub.execute_input":"2025-08-29T07:53:36.001764Z","iopub.status.idle":"2025-08-29T07:53:36.009192Z","shell.execute_reply.started":"2025-08-29T07:53:36.001748Z","shell.execute_reply":"2025-08-29T07:53:36.008467Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## **0.3. Feature importance**","metadata":{}},{"cell_type":"code","source":"def custom_logit_predictor(*tup_tensor_data, data_folder):\n    global added_softmax\n    added_softmax = True\n\n    if cuda:\n        model_dict['VAE_multi'].to(device)\n    model_dict['VAE_multi'].eval()\n\n    tup_tensor_data = tuple(tensor_data.to(device) if cuda else tensor_data \n                           for tensor_data in tup_tensor_data)\n\n    data_tr_list, data_trte_list, trte_idx = preprocessing_data(tup_tensor_data, data_folder)\n    with torch.set_grad_enabled(True):\n        predictions = model_dict['VAE_multi'].infer(data_trte_list)\n    predictions = predictions[trte_idx[\"te\"],:]\n    if added_softmax:\n        predictions = F.softmax(predictions, dim=1)\n\n    return predictions\n\nmodel_dict=None\ndef load_model(data_folder, model_folder):\n    data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(data_folder, view_list, postfix_tr='_tr', postfix_te='_val')\n    dim_list = [x.shape[1] for x in data_tr_list]\n\n    global model_dict\n    model_dict = init_model_dict_multi(view_list,\n                    input_dim, latent_space_dim, \n                    level_2_dim, level_3_dim,\n                    level_4_dim, \n                    classifier_1_dim, class_num)\n    print(model_folder)\n    model_dict = load_model_dict(model_folder, model_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:10:48.213173Z","iopub.execute_input":"2025-08-29T08:10:48.213471Z","iopub.status.idle":"2025-08-29T08:10:48.220053Z","shell.execute_reply.started":"2025-08-29T08:10:48.213451Z","shell.execute_reply":"2025-08-29T08:10:48.219291Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## **0.4. Metrics**","metadata":{}},{"cell_type":"code","source":"def display_classification_report(\n    n_class,\n    conf_matrix,\n    avg_report,\n    label_mapping_name,\n    cmap=\"Blues\",\n    fmt=\".2%\",\n    annot=True,\n    path=None,  # str path to save fig. If not None\n    shown=True,\n):\n    clf_df = avg_report\n    clf_df.loc[[\"precision\", \"recall\"], \"accuracy\"] = np.nan\n\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_figwidth(12)\n    \n    ConfusionMatrixDisplay(conf_matrix, display_labels=label_mapping_name).plot(cmap=cmap, ax=ax1)\n    \n    sns.heatmap(clf_df.iloc[:-1, :].T, annot=annot, cmap=cmap, robust=True, ax=ax2, fmt=fmt)\n    \n    if path is not None:\n        fig.savefig(path, dpi=300)\n    if shown:\n        plt.show()\n    else:\n        plt.close(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:53:36.028078Z","iopub.execute_input":"2025-08-29T07:53:36.028295Z","iopub.status.idle":"2025-08-29T07:53:36.044296Z","shell.execute_reply.started":"2025-08-29T07:53:36.028281Z","shell.execute_reply":"2025-08-29T07:53:36.043753Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def calculate_average_report(reports):\n    \"\"\"Calculate the average classification report from a list of reports.\"\"\"\n    avg_report = pd.DataFrame(reports[0]).copy()\n    for report in reports[1:]:\n        avg_report += pd.DataFrame(report)\n    avg_report /= len(reports)\n    return avg_report\n\ndef evaluate_model(bool_report=True, _type_data='te'):\n    conf_matrix = np.zeros((num_class, num_class), dtype=int)\n\n    reports = []\n    results = []\n\n    for idx in idx_list:\n        cur_model_folder = f'{model_folder}/{idx}'\n        cur_data_folder = f\"{data_folder}/{idx}/\"\n        load_model(cur_data_folder, cur_model_folder)\n\n        _data_list = []\n\n        _label = np.loadtxt(os.path.join(cur_data_folder, f\"labels_{_type_data}.csv\"), delimiter=',').astype(int)\n\n        for i in view_list:\n            _data_loc = os.path.join(cur_data_folder, f\"{i}_{_type_data}.csv\")\n            _data_list.append(np.loadtxt(_data_loc, delimiter=','))\n        \n        _tensor_data_list = tuple(torch.tensor(np_arr, dtype=torch.float32).to(device) for np_arr in _data_list)\n        pred = custom_logit_predictor(*_tensor_data_list, data_folder=cur_data_folder)\n        pred = np.array(torch.argmax(pred.cpu(), dim=1))\n\n        fold_conf_matrix = confusion_matrix(_label, pred, labels=np.arange(num_class))\n        conf_matrix += fold_conf_matrix\n        \n        acc = accuracy_score(_label, pred)\n        f1_macro = f1_score(_label, pred, average='macro')\n        f1_weighted = f1_score(_label, pred, average='weighted')\n        results.append((idx, acc, f1_macro, f1_weighted))\n\n        # Get classification report for the current fold\n        report = classification_report(_label, pred, target_names=LABEL_MAPPING_NAME, output_dict=True)\n        reports.append(report)\n        \n        \n    avg_report = calculate_average_report(reports)\n\n    if bool_report:\n        if not os.path.exists(\"/kaggle/working/phase1\"):\n            os.makedirs(\"/kaggle/working/phase1\")\n        \n        # Calculate average classification report        \n        # Calculate the average of the models\n        df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'F1 Macro', 'F1 Weighted'])\n        avg_row = ['Average', df['Accuracy'].mean(), df['F1 Macro'].mean(), df['F1 Weighted'].mean()]\n        df.loc[len(df)] = avg_row\n\n        print(df.to_string(index=False))\n\n        # Display confusion matrix and classification report\n        display_classification_report(\n            num_class,\n            conf_matrix,\n            avg_report,\n            LABEL_MAPPING_NAME,\n            path=f\"/kaggle/working/phase1/Evaluate_model_{_type_data}\",\n        )\n\n    return avg_report['macro avg']['f1-score']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:53:36.045064Z","iopub.execute_input":"2025-08-29T07:53:36.045682Z","iopub.status.idle":"2025-08-29T07:53:36.058548Z","shell.execute_reply.started":"2025-08-29T07:53:36.045658Z","shell.execute_reply":"2025-08-29T07:53:36.057933Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"retrain = True\nif retrain:\n    model_folder = '/kaggle/working/models'\n    saved_model_dict_folder = model_folder\n    fold_list = [1,2,3,4]\n    for fold_id in fold_list:\n        print(f'idx data: {fold_id}')\n\n        data_folder_idx = f'{data_folder}/{fold_id}'\n        model_folder_idx = f'{model_folder}/{fold_id}'\n        \n        \n        # Run main.py with all required arguments\n        !python '{train_file}' \\\n            '{view_list}' '{hidden_dim}' '{input_dim}' '{latent_space_dim}' \\\n            '{level_2_dim}' '{level_3_dim}' '{level_4_dim}' '{classifier_1_dim}' \\\n            '{class_num}' '{print_hyper}' '{verbose}' '{testonly}' \\\n            '{data_folder_idx}' '{model_folder_idx}' '{saved_model_dict_folder}' \\\n            '{num_epoch}' '{lr}' '{batch_size}' '{patience}' \\\n            '{k_view_list}' '{k_kl}' '{k_c}'\n        \n        print('*'*100)\nelse:\n    model_folder = f'/kaggle/input/{dataset_name}/models'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T07:53:36.059320Z","iopub.execute_input":"2025-08-29T07:53:36.059561Z","iopub.status.idle":"2025-08-29T07:54:13.643058Z","shell.execute_reply.started":"2025-08-29T07:53:36.059539Z","shell.execute_reply":"2025-08-29T07:54:13.642108Z"}},"outputs":[{"name":"stdout","text":"idx data: 1\ncuda: True\nRandom seed set as 42\n\nTraining...\nEarly stop at epoch 35th after 23 epochs not increasing score from epoch 12th with best score 0.8169450496247882\nEarly stopping triggered. Using best model from epoch 12\n****************************************************************************************************\nidx data: 2\ncuda: True\nRandom seed set as 42\n\nTraining...\nEarly stop at epoch 59th after 23 epochs not increasing score from epoch 36th with best score 0.8889506859473489\nEarly stopping triggered. Using best model from epoch 36\n****************************************************************************************************\nidx data: 3\ncuda: True\nRandom seed set as 42\n\nTraining...\nEarly stop at epoch 48th after 23 epochs not increasing score from epoch 25th with best score 0.8110668084352294\nEarly stopping triggered. Using best model from epoch 25\n****************************************************************************************************\nidx data: 4\ncuda: True\nRandom seed set as 42\n\nTraining...\nEarly stop at epoch 30th after 23 epochs not increasing score from epoch 7th with best score 0.7748035914702582\nEarly stopping triggered. Using best model from epoch 7\n****************************************************************************************************\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"evaluate_model(_type_data='tr')\nevaluate_model(_type_data='val')\nevaluate_model(_type_data='te')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:10:53.203947Z","iopub.execute_input":"2025-08-29T08:10:53.204228Z","iopub.status.idle":"2025-08-29T08:10:53.821361Z","shell.execute_reply.started":"2025-08-29T08:10:53.204207Z","shell.execute_reply":"2025-08-29T08:10:53.820475Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/models/1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1697701660.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'te'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2253173939.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(bool_report, _type_data)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcur_model_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{model_folder}/{idx}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcur_data_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{data_folder}/{idx}/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_data_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_model_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0m_data_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3376646871.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(data_folder, model_folder)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     classifier_1_dim, class_num)\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/kaggle/working/thesis/models_VAE/utils.py\u001b[0m in \u001b[0;36mload_model_dict\u001b[0;34m(folder, model_dict)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#            print(\"Module {:} loaded!\".format(module))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:{:}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WARNING: Module {:} from model_dict is not loaded!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL models.VAE_multi was not an allowed global by default. Please use `torch.serialization.add_safe_globals([VAE_multi])` or the `torch.serialization.safe_globals([VAE_multi])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."],"ename":"UnpicklingError","evalue":"Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL models.VAE_multi was not an allowed global by default. Please use `torch.serialization.add_safe_globals([VAE_multi])` or the `torch.serialization.safe_globals([VAE_multi])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.","output_type":"error"}],"execution_count":22}]}