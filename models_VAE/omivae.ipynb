{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11454195,"sourceType":"datasetVersion","datasetId":5211395}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! git clone https://github.com/tangha1004/thesis.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd '/kaggle/working/thesis'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! git pull origin main","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **0. Import**","metadata":{}},{"cell_type":"markdown","source":"## **0.1. Import basic libraries**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport os\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display, HTML\n!pip install watermark --quiet\nimport random\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay,\n    accuracy_score,\n)\n\n%cd '/kaggle/working/thesis/models_VAE'\nfrom models import init_model_dict_multi\nfrom utils import save_model_dict, load_model_dict\nfrom train_test import prepare_trte_data, train_test, train_epoch, test_epoch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sklearn\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nimport copy\nfrom sklearn.compose import ColumnTransformer \nfrom IPython.display import Markdown\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\nfrom scipy.stats import mode\nfrom datetime import datetime\n\n!pip install captum --quiet\nfrom captum.attr import IntegratedGradients, GradientShap","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cuda = True if torch.cuda.is_available() else False\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'cuda: {cuda}')\n\ndef set_seed(seed: int = 42) -> None:\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    print(f\"Random seed set as {seed}\")\n\n# Config\nrseed = 42\nset_seed(rseed)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **0.2. List hyperparameters**","metadata":{}},{"cell_type":"code","source":"view_list = [1,2,3]\nhidden_dim = [1024, 1024, 1024]\ninput_dim = [2000, 2000, 2000]\nlatent_space_dim = (len(view_list) - 1) * 256\nlevel_2_dim = [1024, 1024, 1024]\nlevel_3_dim = [512, 512, 512]\n# num_omics x level_2_dim ---> level_4_dim\nlevel_4_dim = len(view_list) * 256\nclassifier_1_dim = (len(view_list) - 1) * 128\nclass_num = 4\n\nprint_hyper = False\nverbose = False\ntestonly = False\n\ndataset_name = 'tcga-gbm-methxgexcnv-2000-3-omics'\nCOHORT = 'TCGA_GBM_METHxGExCNV_2000x2000x2000_MinMaxScaler'\ndata_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\nmodel_folder = '/kaggle/working/models'\ntrain_file = '/kaggle/working/thesis/models_VAE/main.py'\n\nnum_epoch = 200\nlr = 0.001\nbatch_size = 32\npatience = 23\nk_view_list = [1.0, 1.0, 1.0]\nk_kl = 1.0\nk_c = 1.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"get_name = COHORT.count('_') + 3\n\npostfix_tr = '_tr'\npostfix_te = '_val'\n\ndata_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\nmodel_folder = '/kaggle/working/models'\ntrain_file = '/kaggle/working/thesis/models_VAE/main.py'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loc_file_json_id_omic = data_folder + '/1/dct_index_subtype.json'\nwith open(loc_file_json_id_omic) as file_json_id_omic:\n    dct_LABEL_MAPPING_NAME = json.load(file_json_id_omic)\n    # dct_LABEL_MAPPING_NAME = {int(k): v for k,v in dct_LABEL_MAPPING_NAME.items()} # convert str number key to int\nLABEL_MAPPING_NAME = dct_LABEL_MAPPING_NAME.values()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for fold_id in [3]:\n#     print(f'idx data: {fold_id}')\n    tmp = list(LABEL_MAPPING_NAME)\n    label_files = ['tr', 'te', 'val']\n    dict = {\n        'tr': 'Train set',\n        'te': 'Test set',\n        'val': 'Validation set'\n    }\n    \n    print('\\nCount per Subtypes: \\n')\n    for label_file in label_files:\n        df = pd.read_csv(f'{data_folder}/{fold_id}/labels_{label_file}.csv', header=None, names=['subtypes'])\n        subtype_counts = df['subtypes'].value_counts().sort_index()\n        \n        print(f'{dict[label_file]}')\n        \n        res = {}\n        for subtype, count in subtype_counts.items():\n            res[tmp[subtype]] = count\n\n        print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')\n    \n    print('\\nCount Samples: \\n')\n    for idx in view_list:\n        res = {}\n        for label_file in label_files:\n            df = pd.read_csv(f'{data_folder}/{fold_id}/{idx}_{label_file}.csv', header=None)\n            res[dict[label_file]] = df.shape[0]\n            \n        print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')\n    \n    print('\\nCount Features: \\n')\n    res={}\n    for idx in view_list:\n        df = pd.read_csv(f'{data_folder}/{fold_id}/{idx}_featname.csv', header=None, names=['featname'])\n        res[f\"Omic {idx}\"] = df.shape[0]\n        \n    print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"added_softmax = False\n\ndef preprocessing_data(tup_tensor_test_data, data_folder):\n    data_tr_list = []\n    data_te_list = []\n    \n    for i in view_list:\n        data_tr_list.append(torch.tensor(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','),dtype=torch.float32))\n        data_te_list.append(tup_tensor_test_data[i-1])\n        if cuda:\n            data_tr_list[i-1] = data_tr_list[i-1].to(device)\n            data_te_list[i-1] = data_te_list[i-1].to(device)       \n\n    num_tr = data_tr_list[0].shape[0]\n    num_te = data_te_list[0].shape[0]\n    trte_idx = {}\n    trte_idx[\"tr\"] = list(range(num_tr))\n    trte_idx[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n\n    num_view = len(view_list)\n    data_tensor_list = []\n    for i in range(num_view):\n        data_tensor_list.append(torch.cat((data_tr_list[i], data_te_list[i]), axis=0))\n        if cuda:\n            data_tensor_list[i] = data_tensor_list[i].to(device)#cuda()\n    \n    data_train_list = []\n    data_trte_list = []\n    for i in range(len(data_tensor_list)):\n        data_train_list.append(data_tensor_list[i][trte_idx[\"tr\"]].clone())\n\n        tup_seq_data = (data_tensor_list[i][trte_idx[\"tr\"]].clone(), data_tensor_list[i][trte_idx[\"te\"]].clone())\n        data_trte_list.append(\n            torch.cat(tup_seq_data,axis=0)\n        )\n    return data_train_list, data_trte_list,trte_idx","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **0.3. Feature importance**","metadata":{}},{"cell_type":"code","source":"def custom_logit_predictor(*tup_tensor_data, data_folder):\n    global added_softmax\n    added_softmax = True\n\n    if cuda:\n        model_dict['VAE_multi'].to(device)\n    model_dict['VAE_multi'].eval()\n\n    tup_tensor_data = tuple(tensor_data.to(device) if cuda else tensor_data \n                           for tensor_data in tup_tensor_data)\n\n    data_tr_list, data_trte_list, trte_idx = preprocessing_data(tup_tensor_data, data_folder)\n    with torch.set_grad_enabled(True):\n        predictions = model_dict['VAE_multi'].infer(data_trte_list)\n    predictions = predictions[trte_idx[\"te\"],:]\n    if added_softmax:\n        predictions = F.softmax(predictions, dim=1)\n\n    return predictions\n\nmodel_dict=None\ndef load_model(data_folder, model_folder):\n    data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(data_folder, view_list, postfix_tr='_tr', postfix_te='_val')\n    dim_list = [x.shape[1] for x in data_tr_list]\n\n    global model_dict\n    model_dict = init_model_dict(num_class, dim_list, hidden_dim)\n    print(model_folder)\n    model_dict = load_model_dict(model_folder, model_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **0.4. Metrics**","metadata":{}},{"cell_type":"code","source":"def display_classification_report(\n    n_class,\n    conf_matrix,\n    avg_report,\n    label_mapping_name,\n    cmap=\"Blues\",\n    fmt=\".2%\",\n    annot=True,\n    path=None,  # str path to save fig. If not None\n    shown=True,\n):\n    clf_df = avg_report\n    clf_df.loc[[\"precision\", \"recall\"], \"accuracy\"] = np.nan\n\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_figwidth(12)\n    \n    ConfusionMatrixDisplay(conf_matrix, display_labels=label_mapping_name).plot(cmap=cmap, ax=ax1)\n    \n    sns.heatmap(clf_df.iloc[:-1, :].T, annot=annot, cmap=cmap, robust=True, ax=ax2, fmt=fmt)\n    \n    if path is not None:\n        fig.savefig(path, dpi=300)\n    if shown:\n        plt.show()\n    else:\n        plt.close(fig)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_average_report(reports):\n    \"\"\"Calculate the average classification report from a list of reports.\"\"\"\n    avg_report = pd.DataFrame(reports[0]).copy()\n    for report in reports[1:]:\n        avg_report += pd.DataFrame(report)\n    avg_report /= len(reports)\n    return avg_report\n\ndef evaluate_model(bool_report=True, _type_data='te'):\n    conf_matrix = np.zeros((num_class, num_class), dtype=int)\n\n    reports = []\n    results = []\n\n    for idx in idx_list:\n        cur_model_folder = f'{model_folder}/{idx}'\n        cur_data_folder = f\"{data_folder}/{idx}/\"\n        load_model(cur_data_folder, cur_model_folder)\n\n        _data_list = []\n\n        _label = np.loadtxt(os.path.join(cur_data_folder, f\"labels_{_type_data}.csv\"), delimiter=',').astype(int)\n\n        for i in view_list:\n            _data_loc = os.path.join(cur_data_folder, f\"{i}_{_type_data}.csv\")\n            _data_list.append(np.loadtxt(_data_loc, delimiter=','))\n        \n        _tensor_data_list = tuple(torch.tensor(np_arr, dtype=torch.float32).to(device) for np_arr in _data_list)\n        pred = custom_logit_predictor(*_tensor_data_list, data_folder=cur_data_folder)\n        pred = np.array(torch.argmax(pred.cpu(), dim=1))\n\n        fold_conf_matrix = confusion_matrix(_label, pred, labels=np.arange(num_class))\n        conf_matrix += fold_conf_matrix\n        \n        acc = accuracy_score(_label, pred)\n        f1_macro = f1_score(_label, pred, average='macro')\n        f1_weighted = f1_score(_label, pred, average='weighted')\n        results.append((idx, acc, f1_macro, f1_weighted))\n\n        # Get classification report for the current fold\n        report = classification_report(_label, pred, target_names=LABEL_MAPPING_NAME, output_dict=True)\n        reports.append(report)\n        \n        \n    avg_report = calculate_average_report(reports)\n\n    if bool_report:\n        if not os.path.exists(\"/kaggle/working/phase1\"):\n            os.makedirs(\"/kaggle/working/phase1\")\n        \n        # Calculate average classification report        \n        # Calculate the average of the models\n        df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'F1 Macro', 'F1 Weighted'])\n        avg_row = ['Average', df['Accuracy'].mean(), df['F1 Macro'].mean(), df['F1 Weighted'].mean()]\n        df.loc[len(df)] = avg_row\n\n        print(df.to_string(index=False))\n\n        # Display confusion matrix and classification report\n        display_classification_report(\n            num_class,\n            conf_matrix,\n            avg_report,\n            LABEL_MAPPING_NAME,\n            path=f\"/kaggle/working/phase1/Evaluate_model_{_type_data}\",\n        )\n\n    return avg_report['macro avg']['f1-score']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"retrain = True\nif retrain:\n    model_folder = '/kaggle/working/models'\n    saved_model_dict_folder = model_folder\n    \n    # Use fold_id 3 as shown in your notebook\n    for fold_id in [4]:\n        print(f'idx data: {fold_id}')\n\n        data_folder_idx = f'{data_folder}/{fold_id}'\n        model_folder_idx = f'{model_folder}/{fold_id}'\n        \n        # Format values for command line\n        view_list_str = str(view_list).replace(' ', '')\n        hidden_dim_str = str(hidden_dim).replace(' ', '')\n        input_dim_str = str(input_dim).replace(' ', '')\n        latent_space_dim_str = f'[{latent_space_dim}]'\n        level_2_dim_str = str(level_2_dim).replace(' ', '')\n        level_3_dim_str = str(level_3_dim).replace(' ', '')\n        level_4_dim_str = f'{level_4_dim}'\n        classifier_1_dim_str = f'[{classifier_1_dim}]'\n        class_num_str = f'[{class_num}]'\n        k_view_list_str = str(k_view_list).replace(' ', '')\n\n        # Create directories if they don't exist\n        !mkdir -p {model_folder_idx}\n        \n        # Run main.py with all required arguments\n        !python {train_file} \\\n            {view_list_str} {hidden_dim_str} {input_dim_str} {latent_space_dim_str} \\\n            {level_2_dim_str} {level_3_dim_str} {level_4_dim_str} {classifier_1_dim_str} \\\n            {class_num_str} {print_hyper} {verbose} {testonly} \\\n            {data_folder_idx} {model_folder_idx} {saved_model_dict_folder} \\\n            {num_epoch} {lr} {batch_size} {patience} \\\n            {k_view_list_str} {k_kl} {k_c}\n        \n        print('*'*100)\nelse:\n    model_folder = f'/kaggle/input/{dataset_name}/models'","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}