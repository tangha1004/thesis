{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11454195,"sourceType":"datasetVersion","datasetId":5211395}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! git clone https://github.com/tangha1004/thesis.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:46:29.173622Z","iopub.execute_input":"2025-08-28T02:46:29.173851Z","iopub.status.idle":"2025-08-28T02:46:30.323293Z","shell.execute_reply.started":"2025-08-28T02:46:29.173824Z","shell.execute_reply":"2025-08-28T02:46:30.322412Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'thesis'...\nremote: Enumerating objects: 37, done.\u001b[K\nremote: Counting objects: 100% (37/37), done.\u001b[K\nremote: Compressing objects: 100% (27/27), done.\u001b[K\nremote: Total 37 (delta 17), reused 28 (delta 8), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (37/37), 319.21 KiB | 14.51 MiB/s, done.\nResolving deltas: 100% (17/17), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd '/kaggle/working/thesis'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:46:30.324341Z","iopub.execute_input":"2025-08-28T02:46:30.324684Z","iopub.status.idle":"2025-08-28T02:46:30.331575Z","shell.execute_reply.started":"2025-08-28T02:46:30.324647Z","shell.execute_reply":"2025-08-28T02:46:30.330877Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/thesis\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"! git pull origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:49:01.263101Z","iopub.execute_input":"2025-08-28T02:49:01.263710Z","iopub.status.idle":"2025-08-28T02:49:02.192998Z","shell.execute_reply.started":"2025-08-28T02:49:01.263677Z","shell.execute_reply":"2025-08-28T02:49:02.192090Z"}},"outputs":[{"name":"stdout","text":"remote: Enumerating objects: 7, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (1/1), done.\u001b[K\nremote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\nUnpacking objects: 100% (4/4), 350 bytes | 350.00 KiB/s, done.\nFrom https://github.com/tangha1004/thesis\n * branch            main       -> FETCH_HEAD\n   7f14f48..ebac21d  main       -> origin/main\nUpdating 7f14f48..ebac21d\nFast-forward\n models_VAE/models.py | 6 \u001b[32m+++\u001b[m\u001b[31m---\u001b[m\n 1 file changed, 3 insertions(+), 3 deletions(-)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# **0. Import**","metadata":{}},{"cell_type":"markdown","source":"## **0.1. Import basic libraries**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport os\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display, HTML\n!pip install watermark --quiet\nimport random\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay,\n    accuracy_score,\n)\n\n%cd '/kaggle/working/thesis/models_VAE'\nfrom models import init_model_dict_multi\nfrom utils import save_model_dict, load_model_dict\nfrom train_test import prepare_trte_data, train_test, train_epoch, test_epoch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:46:31.051495Z","iopub.execute_input":"2025-08-28T02:46:31.051788Z","iopub.status.idle":"2025-08-28T02:46:40.313239Z","shell.execute_reply.started":"2025-08-28T02:46:31.051753Z","shell.execute_reply":"2025-08-28T02:46:40.312454Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/thesis/models_VAE\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import sklearn\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nimport copy\nfrom sklearn.compose import ColumnTransformer \nfrom IPython.display import Markdown\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\nfrom scipy.stats import mode\nfrom datetime import datetime\n\n!pip install captum --quiet\nfrom captum.attr import IntegratedGradients, GradientShap","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:46:40.314092Z","iopub.execute_input":"2025-08-28T02:46:40.314510Z","iopub.status.idle":"2025-08-28T02:47:49.894905Z","shell.execute_reply.started":"2025-08-28T02:46:40.314486Z","shell.execute_reply":"2025-08-28T02:47:49.894245Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"cuda = True if torch.cuda.is_available() else False\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'cuda: {cuda}')\n\ndef set_seed(seed: int = 42) -> None:\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    print(f\"Random seed set as {seed}\")\n\n# Config\nrseed = 42\nset_seed(rseed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:47:49.895899Z","iopub.execute_input":"2025-08-28T02:47:49.896205Z","iopub.status.idle":"2025-08-28T02:47:49.906665Z","shell.execute_reply.started":"2025-08-28T02:47:49.896146Z","shell.execute_reply":"2025-08-28T02:47:49.905974Z"}},"outputs":[{"name":"stdout","text":"cuda: True\nRandom seed set as 42\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## **0.2. List hyperparameters**","metadata":{}},{"cell_type":"code","source":"# no space to pass through cmd\nview_list = [1,2,3]\nhidden_dim = [1024,1024,1024]\ninput_dim = [2000,2000,2000]\nlatent_space_dim = int((len(view_list) - 1) * 256)\nlevel_2_dim = [1024,1024,1024]\nlevel_3_dim = [512,512,512]\n# num_omics x level_2_dim ---> level_4_dim\nlevel_4_dim = int(len(view_list) * 256)\nclassifier_1_dim = int((len(view_list) - 1) * 128)\nclass_num = 4\n\nprint_hyper = False\nverbose = False\ntestonly = False\n\ndataset_name = 'tcga-gbm-methxgexcnv-2000-3-omics'\nCOHORT = 'TCGA_GBM_METHxGExCNV_2000x2000x2000_MinMaxScaler'\ndata_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\nmodel_folder = '/kaggle/working/models'\ntrain_file = '/kaggle/working/thesis/models_VAE/main.py'\n\nnum_epoch = 200\nlr = 0.001\nbatch_size = 32\npatience = 23\nk_view_list = [1.0,1.0,1.0]\nk_kl = 1.0\nk_c = 1.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:47:49.907466Z","iopub.execute_input":"2025-08-28T02:47:49.907718Z","iopub.status.idle":"2025-08-28T02:47:49.923380Z","shell.execute_reply.started":"2025-08-28T02:47:49.907702Z","shell.execute_reply":"2025-08-28T02:47:49.922701Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"get_name = COHORT.count('_') + 3\n\npostfix_tr = '_tr'\npostfix_te = '_val'\n\ndata_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\nmodel_folder = '/kaggle/working/models'\ntrain_file = '/kaggle/working/thesis/models_VAE/main.py'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:47:49.924141Z","iopub.execute_input":"2025-08-28T02:47:49.924589Z","iopub.status.idle":"2025-08-28T02:47:49.935738Z","shell.execute_reply.started":"2025-08-28T02:47:49.924563Z","shell.execute_reply":"2025-08-28T02:47:49.935216Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"loc_file_json_id_omic = data_folder + '/1/dct_index_subtype.json'\nwith open(loc_file_json_id_omic) as file_json_id_omic:\n    dct_LABEL_MAPPING_NAME = json.load(file_json_id_omic)\n    # dct_LABEL_MAPPING_NAME = {int(k): v for k,v in dct_LABEL_MAPPING_NAME.items()} # convert str number key to int\nLABEL_MAPPING_NAME = dct_LABEL_MAPPING_NAME.values()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:47:49.938047Z","iopub.execute_input":"2025-08-28T02:47:49.938457Z","iopub.status.idle":"2025-08-28T02:47:49.965490Z","shell.execute_reply.started":"2025-08-28T02:47:49.938441Z","shell.execute_reply":"2025-08-28T02:47:49.965030Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"for fold_id in [3]:\n#     print(f'idx data: {fold_id}')\n    tmp = list(LABEL_MAPPING_NAME)\n    label_files = ['tr', 'te', 'val']\n    dict = {\n        'tr': 'Train set',\n        'te': 'Test set',\n        'val': 'Validation set'\n    }\n    \n    print('\\nCount per Subtypes: \\n')\n    for label_file in label_files:\n        df = pd.read_csv(f'{data_folder}/{fold_id}/labels_{label_file}.csv', header=None, names=['subtypes'])\n        subtype_counts = df['subtypes'].value_counts().sort_index()\n        \n        print(f'{dict[label_file]}')\n        \n        res = {}\n        for subtype, count in subtype_counts.items():\n            res[tmp[subtype]] = count\n\n        print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')\n    \n    print('\\nCount Samples: \\n')\n    for idx in view_list:\n        res = {}\n        for label_file in label_files:\n            df = pd.read_csv(f'{data_folder}/{fold_id}/{idx}_{label_file}.csv', header=None)\n            res[dict[label_file]] = df.shape[0]\n            \n        print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')\n    \n    print('\\nCount Features: \\n')\n    res={}\n    for idx in view_list:\n        df = pd.read_csv(f'{data_folder}/{fold_id}/{idx}_featname.csv', header=None, names=['featname'])\n        res[f\"Omic {idx}\"] = df.shape[0]\n        \n    print(pd.DataFrame(res, index=[0]).to_string(index=False), '\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:47:49.966055Z","iopub.execute_input":"2025-08-28T02:47:49.966247Z","iopub.status.idle":"2025-08-28T02:47:50.811223Z","shell.execute_reply.started":"2025-08-28T02:47:49.966234Z","shell.execute_reply":"2025-08-28T02:47:50.810514Z"}},"outputs":[{"name":"stdout","text":"\nCount per Subtypes: \n\nTrain set\n Classical  Mesenchymal  Neural  Proneural\n        43           48      28         43 \n\nTest set\n Classical  Mesenchymal  Neural  Proneural\n        14           16       9         15 \n\nValidation set\n Classical  Mesenchymal  Neural  Proneural\n        14           17       9         14 \n\n\nCount Samples: \n\n Train set  Test set  Validation set\n       162        54              54 \n\n Train set  Test set  Validation set\n       162        54              54 \n\n Train set  Test set  Validation set\n       162        54              54 \n\n\nCount Features: \n\n Omic 1  Omic 2  Omic 3\n   2000    2000    2000 \n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"added_softmax = False\n\ndef preprocessing_data(tup_tensor_test_data, data_folder):\n    data_tr_list = []\n    data_te_list = []\n    \n    for i in view_list:\n        data_tr_list.append(torch.tensor(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','),dtype=torch.float32))\n        data_te_list.append(tup_tensor_test_data[i-1])\n        if cuda:\n            data_tr_list[i-1] = data_tr_list[i-1].to(device)\n            data_te_list[i-1] = data_te_list[i-1].to(device)       \n\n    num_tr = data_tr_list[0].shape[0]\n    num_te = data_te_list[0].shape[0]\n    trte_idx = {}\n    trte_idx[\"tr\"] = list(range(num_tr))\n    trte_idx[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n\n    num_view = len(view_list)\n    data_tensor_list = []\n    for i in range(num_view):\n        data_tensor_list.append(torch.cat((data_tr_list[i], data_te_list[i]), axis=0))\n        if cuda:\n            data_tensor_list[i] = data_tensor_list[i].to(device)#cuda()\n    \n    data_train_list = []\n    data_trte_list = []\n    for i in range(len(data_tensor_list)):\n        data_train_list.append(data_tensor_list[i][trte_idx[\"tr\"]].clone())\n\n        tup_seq_data = (data_tensor_list[i][trte_idx[\"tr\"]].clone(), data_tensor_list[i][trte_idx[\"te\"]].clone())\n        data_trte_list.append(\n            torch.cat(tup_seq_data,axis=0)\n        )\n    return data_train_list, data_trte_list,trte_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:47:50.812026Z","iopub.execute_input":"2025-08-28T02:47:50.812571Z","iopub.status.idle":"2025-08-28T02:47:50.818871Z","shell.execute_reply.started":"2025-08-28T02:47:50.812552Z","shell.execute_reply":"2025-08-28T02:47:50.818341Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## **0.3. Feature importance**","metadata":{}},{"cell_type":"code","source":"def custom_logit_predictor(*tup_tensor_data, data_folder):\n    global added_softmax\n    added_softmax = True\n\n    if cuda:\n        model_dict['VAE_multi'].to(device)\n    model_dict['VAE_multi'].eval()\n\n    tup_tensor_data = tuple(tensor_data.to(device) if cuda else tensor_data \n                           for tensor_data in tup_tensor_data)\n\n    data_tr_list, data_trte_list, trte_idx = preprocessing_data(tup_tensor_data, data_folder)\n    with torch.set_grad_enabled(True):\n        predictions = model_dict['VAE_multi'].infer(data_trte_list)\n    predictions = predictions[trte_idx[\"te\"],:]\n    if added_softmax:\n        predictions = F.softmax(predictions, dim=1)\n\n    return predictions\n\nmodel_dict=None\ndef load_model(data_folder, model_folder):\n    data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(data_folder, view_list, postfix_tr='_tr', postfix_te='_val')\n    dim_list = [x.shape[1] for x in data_tr_list]\n\n    global model_dict\n    model_dict = init_model_dict(num_class, dim_list, hidden_dim)\n    print(model_folder)\n    model_dict = load_model_dict(model_folder, model_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:47:50.819539Z","iopub.execute_input":"2025-08-28T02:47:50.820352Z","iopub.status.idle":"2025-08-28T02:47:50.834517Z","shell.execute_reply.started":"2025-08-28T02:47:50.820334Z","shell.execute_reply":"2025-08-28T02:47:50.833811Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## **0.4. Metrics**","metadata":{}},{"cell_type":"code","source":"def display_classification_report(\n    n_class,\n    conf_matrix,\n    avg_report,\n    label_mapping_name,\n    cmap=\"Blues\",\n    fmt=\".2%\",\n    annot=True,\n    path=None,  # str path to save fig. If not None\n    shown=True,\n):\n    clf_df = avg_report\n    clf_df.loc[[\"precision\", \"recall\"], \"accuracy\"] = np.nan\n\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_figwidth(12)\n    \n    ConfusionMatrixDisplay(conf_matrix, display_labels=label_mapping_name).plot(cmap=cmap, ax=ax1)\n    \n    sns.heatmap(clf_df.iloc[:-1, :].T, annot=annot, cmap=cmap, robust=True, ax=ax2, fmt=fmt)\n    \n    if path is not None:\n        fig.savefig(path, dpi=300)\n    if shown:\n        plt.show()\n    else:\n        plt.close(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:47:50.835237Z","iopub.execute_input":"2025-08-28T02:47:50.835501Z","iopub.status.idle":"2025-08-28T02:47:50.852483Z","shell.execute_reply.started":"2025-08-28T02:47:50.835483Z","shell.execute_reply":"2025-08-28T02:47:50.851734Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def calculate_average_report(reports):\n    \"\"\"Calculate the average classification report from a list of reports.\"\"\"\n    avg_report = pd.DataFrame(reports[0]).copy()\n    for report in reports[1:]:\n        avg_report += pd.DataFrame(report)\n    avg_report /= len(reports)\n    return avg_report\n\ndef evaluate_model(bool_report=True, _type_data='te'):\n    conf_matrix = np.zeros((num_class, num_class), dtype=int)\n\n    reports = []\n    results = []\n\n    for idx in idx_list:\n        cur_model_folder = f'{model_folder}/{idx}'\n        cur_data_folder = f\"{data_folder}/{idx}/\"\n        load_model(cur_data_folder, cur_model_folder)\n\n        _data_list = []\n\n        _label = np.loadtxt(os.path.join(cur_data_folder, f\"labels_{_type_data}.csv\"), delimiter=',').astype(int)\n\n        for i in view_list:\n            _data_loc = os.path.join(cur_data_folder, f\"{i}_{_type_data}.csv\")\n            _data_list.append(np.loadtxt(_data_loc, delimiter=','))\n        \n        _tensor_data_list = tuple(torch.tensor(np_arr, dtype=torch.float32).to(device) for np_arr in _data_list)\n        pred = custom_logit_predictor(*_tensor_data_list, data_folder=cur_data_folder)\n        pred = np.array(torch.argmax(pred.cpu(), dim=1))\n\n        fold_conf_matrix = confusion_matrix(_label, pred, labels=np.arange(num_class))\n        conf_matrix += fold_conf_matrix\n        \n        acc = accuracy_score(_label, pred)\n        f1_macro = f1_score(_label, pred, average='macro')\n        f1_weighted = f1_score(_label, pred, average='weighted')\n        results.append((idx, acc, f1_macro, f1_weighted))\n\n        # Get classification report for the current fold\n        report = classification_report(_label, pred, target_names=LABEL_MAPPING_NAME, output_dict=True)\n        reports.append(report)\n        \n        \n    avg_report = calculate_average_report(reports)\n\n    if bool_report:\n        if not os.path.exists(\"/kaggle/working/phase1\"):\n            os.makedirs(\"/kaggle/working/phase1\")\n        \n        # Calculate average classification report        \n        # Calculate the average of the models\n        df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'F1 Macro', 'F1 Weighted'])\n        avg_row = ['Average', df['Accuracy'].mean(), df['F1 Macro'].mean(), df['F1 Weighted'].mean()]\n        df.loc[len(df)] = avg_row\n\n        print(df.to_string(index=False))\n\n        # Display confusion matrix and classification report\n        display_classification_report(\n            num_class,\n            conf_matrix,\n            avg_report,\n            LABEL_MAPPING_NAME,\n            path=f\"/kaggle/working/phase1/Evaluate_model_{_type_data}\",\n        )\n\n    return avg_report['macro avg']['f1-score']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:47:50.853152Z","iopub.execute_input":"2025-08-28T02:47:50.853729Z","iopub.status.idle":"2025-08-28T02:47:50.866889Z","shell.execute_reply.started":"2025-08-28T02:47:50.853706Z","shell.execute_reply":"2025-08-28T02:47:50.866387Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"retrain = True\nif retrain:\n    model_folder = '/kaggle/working/models'\n    saved_model_dict_folder = model_folder\n    \n    for fold_id in [4]:\n        print(f'idx data: {fold_id}')\n\n        data_folder_idx = f'{data_folder}/{fold_id}'\n        model_folder_idx = f'{model_folder}/{fold_id}'\n        \n        \n        # Run main.py with all required arguments\n        !python '{train_file}' \\\n            '{view_list}' '{hidden_dim}' '{input_dim}' '{latent_space_dim}' \\\n            '{level_2_dim}' '{level_3_dim}' '{level_4_dim}' '{classifier_1_dim}' \\\n            '{class_num}' '{print_hyper}' '{verbose}' '{testonly}' \\\n            '{data_folder_idx}' '{model_folder_idx}' '{saved_model_dict_folder}' \\\n            '{num_epoch}' '{lr}' '{batch_size}' '{patience}' \\\n            '{k_view_list}' '{k_kl}' '{k_c}'\n        \n        print('*'*100)\nelse:\n    model_folder = f'/kaggle/input/{dataset_name}/models'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T02:49:09.982510Z","iopub.execute_input":"2025-08-28T02:49:09.982815Z","iopub.status.idle":"2025-08-28T02:49:13.345319Z","shell.execute_reply.started":"2025-08-28T02:49:09.982788Z","shell.execute_reply":"2025-08-28T02:49:13.344408Z"}},"outputs":[{"name":"stdout","text":"idx data: 4\nDEBUG <class 'int'>\nDEBUG <class 'int'>\n1024\nDEBUG <class 'int'>\nDEBUG <class 'int'>\n1024\nDEBUG <class 'int'>\nDEBUG <class 'int'>\n1024\nDEBUG <class 'int'>\nDEBUG <class 'int'>\n512\nDEBUG <class 'int'>\nDEBUG <class 'int'>\n512\nDEBUG <class 'int'>\nDEBUG <class 'int'>\n512\nDEBUG <class 'int'>\nDEBUG <class 'int'>\n768\nDEBUG <class 'int'>\nDEBUG <class 'list'>\n[512]\nTraceback (most recent call last):\n  File \"/kaggle/working/thesis/models_VAE/main.py\", line 107, in <module>\n    model_dict = train_test(\n                 ^^^^^^^^^^^\n  File \"/kaggle/working/thesis/models_VAE/train_test.py\", line 204, in train_test\n    model_dict = init_model_dict_multi(view_list,\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/thesis/models_VAE/models.py\", line 50, in init_model_dict_multi\n    model_dict['VAE_multi'] = VAE_multi(view_list,\n                              ^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/thesis/models_VAE/models.py\", line 197, in __init__\n    self.e_fc4_mean = self.fc_layer(level_4_dim, latent_space_dim, activation=0)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/thesis/models_VAE/models.py\", line 227, in fc_layer\n    nn.Linear(in_dim, out_dim),\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 106, in __init__\n    torch.empty((out_features, in_features), **factory_kwargs)\nTypeError: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n\n****************************************************************************************************\n","output_type":"stream"}],"execution_count":18}]}